
=================================================================
========   Liste des étapes à Suivre pour utiliser Kafka ======== 
=================================================================
   !!! se placer dans le repertoire des scipts pour exécuter ces commandes : 

  étape  01 : Lancement de ZooKeeper   (qui se base le fichier zookeeper.properties)
	 Exécuter le scipt suivant : ./run-zookeeper.sh  	

  étape  02 : Lancement des serveurs Kafka  dans des fenêtres séparement 
  	Exécuter le scipt suivant : ./run-kafka-0.sh
	Exécuter le scipt suivant : ./run-kafka-1.sh
	Exécuter le scipt suivant : ./run-kafka-2.sh
 
  étape  03 : Création du/des Topic
  	Exécuter le scipt suivant : ./create-topic-replication.sh
 
  étape  04 : Lister less topics crées"
  	Exécuter le scipt suivant : ./test-topic.sh
 
  étape  05 : Démarrer le Producer  ( !! dans une fenêtre  à part, et vous pouvez saisir les messages après quand vous voulez)
  	Exécuter le scipt suivant :       
	>./run-producer-replication.sh
 
  étape  06 : Démarrer le consumer  ( !! dans une fenêtre  à part , pour mieux voir l'arrivé des messages,  on peut  lancer autant de consumer qu'on veut ) 
  	Exécuter le scipt suivant : ./run-consumer-group.sh
        
        // en cours  ne fonctionne pas encore avec.. Java 
        //Exécuter le scipt suivant : ./run-consumer-group.sh
 
=================================================================
========                   End des étapes                ======== 
=================================================================






 # Facultatif jsute pour les curieux :

== les fichiers de confiuratoions des serveurs :
 - config/zookeeper.properties
 - config/server-0.properties
 - config/server-1.properties
 - config/server-2.properties

== les éléments  à modifier dans ces fichiers  :
  - server-0.properties
	broker.id=0
	port=9092
	log.dirs=./logs/kafka-0


 - server-1.properties
	broker.id=1
	port=9093
	log.dirs=./logs/kafka-1


 - server-2.properties
	broker.id=2
	port=9094
	log.dirs=./logs/kafka-2


# en cour pour lancer un consumer en Java qui sauvegarde dans la base 
javac -cp "../libs/*" ConsumerGroup topiccommit groupGitHub
java -cp "../libs/*":. ConsumerGroup topiccommit groupGitHub



Administration : on peut installer un outils pour manager les clusters et les topics 
======================
$ git clone https://github.com/yahoo/kafka-manager.git
$ cd kafka-manager/
$ ./sbt clean dist
cd target/universal/
unzip kafka-manager-1.3.3.4.zip
cd kafka-manager-1.3.3.4/
ZK_HOSTS=localhost:2181 ./bin/kafka-manager
 http://localhost:9000



références :
==============
https://openclassrooms.com/courses/gerez-des-flux-de-donnees-temps-reel/deployez-et-administrez-un-cluster-kafka



